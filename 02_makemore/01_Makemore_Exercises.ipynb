{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oOjBUVmXDkqs"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/AndrejKarpathy_NN_Hero/names.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "BTBY_g5oD5qO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(path, mode='r').read().splitlines()"
      ],
      "metadata": {
        "id": "upvsbS-BEB9Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = ['.'] + list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "stoi = {c: i for i, c in enumerate(chars)}\n",
        "itos = {i: c for c, i in stoi.items()}"
      ],
      "metadata": {
        "id": "IVMYs4gQFE9d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quadgram"
      ],
      "metadata": {
        "id": "DpwZmZ-4EulN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a training data set\n",
        "\n",
        "x1s = []\n",
        "x2s = []\n",
        "x3s = [] # Can use a 2d Array with 3 Sub Arrays\n",
        "ys = []\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2, ch3, ch4 in zip(chs, chs[1:], chs[2:], chs[3:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        ix3 = stoi[ch3]\n",
        "        ix4 = stoi[ch4]\n",
        "\n",
        "        x1s.append(ix1)\n",
        "        x2s.append(ix2)\n",
        "        x3s.append(ix3)\n",
        "        ys.append(ix4)\n",
        "\n",
        "x1s = torch.tensor(x1s)\n",
        "x2s = torch.tensor(x2s)\n",
        "x3s = torch.tensor(x3s)\n",
        "ys = torch.tensor(ys)\n",
        "print(f\"Total Examples: {ys.nelement()}\")\n",
        "\n",
        "x1enc = F.one_hot(x1s, num_classes=27).float()\n",
        "x2enc = F.one_hot(x2s, num_classes=27).float()\n",
        "x3enc = F.one_hot(x3s, num_classes=27).float()\n",
        "xenc = torch.cat([x1enc, x2enc, x3enc], dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEct6m95EHQ5",
        "outputId": "1e6b7f39-3c79-4026-a888-cb66905a5b33"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Examples: 164080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the network\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((81, 27), generator=g, requires_grad=True)\n",
        "\n",
        "# Produce Output\n",
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "loss = -probs[torch.arange(n), ys].log().mean()\n",
        "\n",
        "print(f'Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZripaF2oHlN9",
        "outputId": "4129707e-b0e2-428b-b696-1b009db8efd1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.368551731109619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Optimize the Network: Gradient Descent\n",
        "n = ys.nelement()\n",
        "\n",
        "for k in range(300):\n",
        "    # Forward Pass\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdims=True)\n",
        "    loss = -probs[torch.arange(n), ys].log().mean()\n",
        "\n",
        "    # Backward Pass\n",
        "    W.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Nudge Weights\n",
        "    W.data += -1 * W.grad\n",
        "print(f'Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap4P8P4SIkQX",
        "outputId": "af07fc7d-8cb3-40d6-fff4-c3e2bcf01194"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.262303352355957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimum loss of 0.0055 is achieved"
      ],
      "metadata": {
        "id": "ptZH4NqiKJYq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for k in range(20):\n",
        "    idx = [0, 0, 0]\n",
        "    wrd = '.'\n",
        "    while True:\n",
        "        x1enc = F.one_hot(torch.tensor([idx[0]]), num_classes=27).float()\n",
        "        x2enc = F.one_hot(torch.tensor([idx[1]]), num_classes=27).float()\n",
        "        x3enc = F.one_hot(torch.tensor(idx[2]), num_classes=27).float().unsqueeze(0)\n",
        "        # Wrap idx[0] in [] - this will produce [1, 27], otherwise it will be [27] and we will have to .unsqueeze it\n",
        "        xenc = torch.cat([x1enc, x2enc, x3enc], dim=1)\n",
        "        logits = xenc @ W\n",
        "        counts = logits.exp()\n",
        "        probs = counts / counts.sum(1, keepdims=True)\n",
        "        ix_next = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
        "        wrd += itos[ix_next]\n",
        "        if ix_next == 0:\n",
        "            break\n",
        "        idx = idx[1:] + [ix_next]\n",
        "    print(wrd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn7uP6KAKMQT",
        "outputId": "a4bb85fd-a5c9-449c-b9f4-017347cafbd7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "..\n",
            ".uoidvdvpkpqga.\n",
            ".uyzftywedvzqfuybftmozckbxgtebwdwdqgaadvdaibedmczphvdaikrwlmtyasdjpicaycfwebfdvvtumpzyfmd.\n",
            ".uojfpffybbgjqbmryqdhoidayaebfjmpypftxd.\n",
            ".nojdmbudmfyfvwpwgapsxhzjiiussszxhpdgaiffibiauilzlglplglmvyapejkrolllllllmpyxywejikuycftvqdmpzhvpchvckmckr.\n",
            ".ytyhwdqztxa.\n",
            ".nzyuisznlyiquiqzavwpocbgdvqmbyayawdw.\n",
            ".n.\n",
            "..\n",
            ".nzzgkfqvxlptqmgycaleevvdvzuipewffmbbxqqgrjxbtearchwdmuzhiouycycdwckdhalglplpgpebidzpulsciqeaydwzuivzpihulgibdhvkdokgtilwlxsstzzgiiuisznzipiqdapbgdwvdwfdmhukbxdvjvpkmykdtnajbfjmbkdqfvwdkbdduihzpuisidzbgpfdvhwbuhstvwtxd.\n",
            ".n.\n",
            ".uy.\n",
            ".htyudtfjtpa.\n",
            ".ynzfisqnlyppggjikullovdmszdfvkbxdqzmfvwxbt.\n",
            "..\n",
            ".n.\n",
            ".hzoigaibudmszxivwdb.\n",
            ".uoisuiogtkvnvqgabmbqdvrqfalaslylgalelgjpqiardyzq.\n",
            ".nsgirqdmhvipagkfdvzainfqbadmfulmskdtcvjtxq.\n",
            "..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigram & Trigram - Train, Test Split"
      ],
      "metadata": {
        "id": "UycFoQujodwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BIGRAM"
      ],
      "metadata": {
        "id": "cQZ3w_nIw45L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BIGRAM\n",
        "\n",
        "xsb = []\n",
        "ysb = []\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs, chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        xsb.append(ix1)\n",
        "        ysb.append(ix2)\n",
        "\n",
        "xsb = torch.tensor(xsb)\n",
        "ysb = torch.tensor(ysb)\n",
        "n = ysb.nelement()\n",
        "print(f\"Total Examples: {n}\")\n",
        "\n",
        "xbenc = F.one_hot(xsb, num_classes=27).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyBKXC2HoihX",
        "outputId": "6ded7a33-b4d8-44b0-c93d-177d19a8f670"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Examples: 228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Split into train (80%) and temp (20% → dev+test)\n",
        "xb_train, xb_temp, yb_train, yb_temp = train_test_split(xbenc, ysb, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Split temp into dev (10%) and test (10%)\n",
        "xb_dev, xb_test, yb_dev, yb_test = train_test_split(xb_temp, yb_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Confirm shapes\n",
        "print(xb_train.shape, yb_train.shape)  # ~80%\n",
        "print(xb_dev.shape, yb_dev.shape)      # ~10%\n",
        "print(xb_test.shape, yb_test.shape)    # ~10%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xuv9cnXpfKk",
        "outputId": "61210b62-9c92-42ab-8b68-e6fce1164761"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182516, 27]) torch.Size([182516])\n",
            "torch.Size([22815, 27]) torch.Size([22815])\n",
            "torch.Size([22815, 27]) torch.Size([22815])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the network\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "Wb = torch.randn((27, 27), generator=g, requires_grad=True)\n",
        "\n",
        "nb_train = yb_train.nelement()\n",
        "# Produce Output\n",
        "logitsb = xb_train @ Wb\n",
        "countsb = logitsb.exp()\n",
        "probsb = countsb / countsb.sum(1, keepdims=True)\n",
        "lossb = -probsb[torch.arange(nb_train), yb_train].log().mean()\n",
        "\n",
        "print(f'Loss: {lossb.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A__oELo4pMwz",
        "outputId": "fc6c233a-1e83-4476-8d4a-e87e581f9b63"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.759887933731079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Optimize the Network: Gradient Descent\n",
        "\n",
        "for k in range(500):\n",
        "    # Forward Pass\n",
        "    logitsb = xb_train @ Wb\n",
        "    countsb = logitsb.exp()\n",
        "    probsb = countsb / countsb.sum(1, keepdims=True)\n",
        "    lossb = -probsb[torch.arange(nb_train), yb_train].log().mean()\n",
        "\n",
        "    # Backward Pass\n",
        "    Wb.grad = None\n",
        "    lossb.backward()\n",
        "\n",
        "    # Nudge Weights\n",
        "    Wb.data += -1 * Wb.grad\n",
        "print(f'Loss: {lossb.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGyIuRgerG4T",
        "outputId": "10a81510-95d4-41da-b24f-eea00123f157"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.506399631500244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalutate the model on dev, test dataset\n",
        "\n",
        "# Dev data\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "logitsb_dev = xb_dev @ Wb\n",
        "countsb_dev = logitsb_dev.exp()\n",
        "probsb_dev = countsb_dev / countsb_dev.sum(1, keepdims=True)\n",
        "\n",
        "# Loss of Dev Data on NN\n",
        "nb_dev = yb_dev.nelement()\n",
        "lossb_dev = -probsb_dev[torch.arange(nb_dev), yb_dev].log().mean().item()\n",
        "\n",
        "print(f\"Loss: {lossb_dev:.4f}\")\n",
        "\n",
        "yb_dev_pred = torch.multinomial(probsb_dev, num_samples=1, replacement=True, generator=g).squeeze()\n",
        "\n",
        "# Accuracy Test\n",
        "accuracyb_dev = (yb_dev_pred == yb_dev).float().mean() * 100\n",
        "print(f\"Bigram Dev accuracy: {accuracyb_dev:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz3HMlgEswCP",
        "outputId": "3a074c3e-6db4-4f90-a301-dbf45281a6e2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.5120\n",
            "Bigram Dev accuracy: 12.2814%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalutate the model on test dataset\n",
        "\n",
        "# Dev data\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "logitsb_test = xb_test @ Wb\n",
        "countsb_test = logitsb_test.exp()\n",
        "probsb_test = countsb_test / countsb_test.sum(1, keepdims=True)\n",
        "\n",
        "# Loss of Dev Data on NN\n",
        "nb_test = yb_test.nelement()\n",
        "lossb_test = -probsb_test[torch.arange(nb_test), yb_test].log().mean().item()\n",
        "\n",
        "print(f\"Loss: {lossb_test:.4f}\")\n",
        "\n",
        "yb_test_pred = torch.multinomial(probsb_test, num_samples=1, replacement=True, generator=g).squeeze()\n",
        "\n",
        "# Accuracy Test\n",
        "accuracyb_test = (yb_test_pred == yb_test).float().mean() * 100\n",
        "print(f\"Bigram Dev accuracy: {accuracyb_test:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB2w3k4buFF0",
        "outputId": "2eeb90aa-f407-4f6e-a067-b4682559fd11"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.5052\n",
            "Bigram Dev accuracy: 12.1543%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRIGRAM"
      ],
      "metadata": {
        "id": "Oo03LP5bw8Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the data\n",
        "xt = []\n",
        "yt = []\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        ix3 = stoi[ch3]\n",
        "        xt.append([ix1, ix2])  # input: two chars\n",
        "        yt.append(ix3)         # output: next char\n",
        "\n",
        "xt = torch.tensor(xt)\n",
        "yt = torch.tensor(yt)\n",
        "nt = yt.nelement()\n",
        "print(f\"Total Trigram Examples: {nt}\")\n",
        "\n",
        "# One-hot encode each of the two input indices, then concatenate to form input of shape [nt, 54]\n",
        "x1enc = F.one_hot(xt[:, 0], num_classes=27)\n",
        "x2enc = F.one_hot(xt[:, 1], num_classes=27)\n",
        "xtenc = torch.cat([x1enc, x2enc], dim=1).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odh2zMVrv4SN",
        "outputId": "bb8b5db4-4c8b-49b2-b03a-d6994f2e8d38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trigram Examples: 196113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "xt_train, xt_temp, yt_train, yt_temp = train_test_split(xtenc, yt, test_size=0.2, random_state=42)\n",
        "xt_dev, xt_test, yt_dev, yt_test = train_test_split(xt_temp, yt_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(xt_train.shape, yt_train.shape)\n",
        "print(xt_dev.shape, yt_dev.shape)\n",
        "print(xt_test.shape, yt_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzjUjgGZxDb5",
        "outputId": "86e5c49f-37a0-4519-9862-b8bd27523682"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([156890, 54]) torch.Size([156890])\n",
            "torch.Size([19611, 54]) torch.Size([19611])\n",
            "torch.Size([19612, 54]) torch.Size([19612])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create network\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "Wt = torch.randn((54, 27), generator=g, requires_grad=True)\n",
        "\n",
        "nt_train = yt_train.nelement()\n",
        "\n",
        "# Training Loop\n",
        "for k in range(500):\n",
        "    # Forward pass\n",
        "    logitst = xt_train @ Wt\n",
        "    countst = logitst.exp()\n",
        "    probst = countst / countst.sum(1, keepdims=True)\n",
        "    losst = -probst[torch.arange(nt_train), yt_train].log().mean()\n",
        "\n",
        "    # Backward pass\n",
        "    Wt.grad = None\n",
        "    losst.backward()\n",
        "\n",
        "    # Update weights\n",
        "    Wt.data += -1 * Wt.grad\n",
        "\n",
        "print(f'Training Loss: {losst.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU6ukmTFxHKQ",
        "outputId": "2b9ba303-73ef-4d17-884b-57fd01ab3591"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.5139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "for k in range(500):\n",
        "    # Forward pass\n",
        "    logitst = xt_train @ Wt\n",
        "    countst = logitst.exp()\n",
        "    probst = countst / countst.sum(1, keepdims=True)\n",
        "    losst = -probst[torch.arange(nt_train), yt_train].log().mean()\n",
        "\n",
        "    # Backward pass\n",
        "    Wt.grad = None\n",
        "    losst.backward()\n",
        "\n",
        "    # Update weights\n",
        "    Wt.data += -1 * Wt.grad\n",
        "\n",
        "print(f'Training Loss: {losst.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP5twicRxphD",
        "outputId": "723ef620-6703-4033-d2d2-afb271d75251"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.3840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dev Data Evaluation\n",
        "nt_dev = yt_dev.nelement()\n",
        "logitst_dev = xt_dev @ Wt\n",
        "countst_dev = logitst_dev.exp()\n",
        "probst_dev = countst_dev / countst_dev.sum(1, keepdim=True)\n",
        "losst_dev = -probst_dev[torch.arange(nt_dev), yt_dev].log().mean().item()\n",
        "print(f\"Trigram Dev Loss: {losst_dev:.4f}\")\n",
        "\n",
        "# Accuracy\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "yt_dev_pred = torch.multinomial(probst_dev, num_samples=1, replacement=True, generator=g).squeeze()\n",
        "accuracyt_dev = (yt_dev_pred == yt_dev).float().mean() * 100\n",
        "print(f\"Trigram Dev Accuracy: {accuracyt_dev:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_jLSUckxaoh",
        "outputId": "b2fb67e9-fcaf-4b8b-8afc-d9ccfae86b6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Dev Loss: 2.3784\n",
            "Trigram Dev Accuracy: 16.0522%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data Evaluation\n",
        "nt_test = yt_test.nelement()\n",
        "logitst_test = xt_test @ Wt\n",
        "countst_test = logitst_test.exp()\n",
        "probst_test = countst_test / countst_test.sum(1, keepdim=True)\n",
        "losst_test = -probst_test[torch.arange(nt_test), yt_test].log().mean().item()\n",
        "print(f\"Trigram Test Loss: {losst_test:.4f}\")\n",
        "\n",
        "yt_test_pred = torch.multinomial(probst_test, num_samples=1, replacement=True, generator=g).squeeze()\n",
        "accuracyt_test = (yt_test_pred == yt_test).float().mean() * 100\n",
        "print(f\"Trigram Test Accuracy: {accuracyt_test:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ8fvuE1yGsA",
        "outputId": "1a76194b-d187-4d1d-a81a-c85860c52cc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Test Loss: 2.3815\n",
            "Trigram Test Accuracy: 15.4548%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the same given data, Trigram produces more accurate results, when compared to bigram"
      ],
      "metadata": {
        "id": "hp7pXIu6yJuU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Regularization of Trigram Model"
      ],
      "metadata": {
        "id": "Qlc5uYpsH1K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define regularization strengths to try\n",
        "lambdas = [0.0, 0.01, 0.1, 1.0, 10.0]\n",
        "best_lambda = None\n",
        "best_dev_loss = float('inf')\n",
        "best_Wt = None\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for lam in lambdas:\n",
        "    # Reset weights\n",
        "    Wt = torch.randn((54, 27), generator=g, requires_grad=True)\n",
        "\n",
        "    # Train the model\n",
        "    for k in range(500):\n",
        "        # Forward pass\n",
        "        logitst = xt_train @ Wt\n",
        "        countst = logitst.exp()\n",
        "        probst = countst / countst.sum(1, keepdims=True)\n",
        "        losst = -probst[torch.arange(yt_train.nelement()), yt_train].log().mean()\n",
        "\n",
        "        # Add L2 regularization\n",
        "        losst += lam * Wt.pow(2).mean()\n",
        "\n",
        "        # Backward pass\n",
        "        Wt.grad = None\n",
        "        losst.backward()\n",
        "        Wt.data += -1 * Wt.grad\n",
        "\n",
        "    # Evaluate on dev set\n",
        "    logitst_dev = xt_dev @ Wt\n",
        "    countst_dev = logitst_dev.exp()\n",
        "    probst_dev = countst_dev / countst_dev.sum(1, keepdim=True)\n",
        "    losst_dev = -probst_dev[torch.arange(yt_dev.nelement()), yt_dev].log().mean().item()\n",
        "\n",
        "    print(f\"Lambda: {lam:.3f}, Dev Loss: {losst_dev:.4f}\")\n",
        "\n",
        "    if losst_dev < best_dev_loss:\n",
        "        best_dev_loss = losst_dev\n",
        "        best_lambda = lam\n",
        "        best_Wt = Wt.detach().clone()\n",
        "\n",
        "print(f\"\\n✅ Best Lambda: {best_lambda}, with Dev Loss: {best_dev_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccp103wgIOVC",
        "outputId": "abab5b0d-b4b7-45ef-ace6-7c34a72713f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambda: 0.000, Dev Loss: 2.5109\n",
            "Lambda: 0.010, Dev Loss: 2.5183\n",
            "Lambda: 0.100, Dev Loss: 2.4818\n",
            "Lambda: 1.000, Dev Loss: 2.4699\n",
            "Lambda: 10.000, Dev Loss: 2.7915\n",
            "\n",
            "✅ Best Lambda: 1.0, with Dev Loss: 2.4699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model with best lambda and evaluate on test data\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "Wt = torch.randn((54, 27), generator=g, requires_grad=True)\n",
        "\n",
        "# Train the model\n",
        "for k in range(500):\n",
        "    # Forward pass\n",
        "    logitst = xt_train @ Wt\n",
        "    countst = logitst.exp()\n",
        "    probst = countst / countst.sum(1, keepdims=True)\n",
        "    losst = -probst[torch.arange(yt_train.nelement()), yt_train].log().mean()\n",
        "\n",
        "    # Add L2 regularization\n",
        "    losst += best_lambda * Wt.pow(2).mean()\n",
        "\n",
        "    # Backward pass\n",
        "    Wt.grad = None\n",
        "    losst.backward()\n",
        "    Wt.data += -1 * Wt.grad\n",
        "\n",
        "logitst = xt_train @ Wt\n",
        "countst = logitst.exp()\n",
        "probst = countst / countst.sum(1, keepdims=True)\n",
        "losst = -probst[torch.arange(yt_train.nelement()), yt_train].log().mean().item()\n",
        "print(f'Train Loss: {losst:.4f}')\n",
        "\n",
        "# Evaluate on dev set\n",
        "logitst_dev = xt_dev @ Wt\n",
        "countst_dev = logitst_dev.exp()\n",
        "probst_dev = countst_dev / countst_dev.sum(1, keepdim=True)\n",
        "losst_dev = -probst_dev[torch.arange(yt_dev.nelement()), yt_dev].log().mean().item()\n",
        "print(f\"Dev Loss: {losst_dev:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "logitst_test = xt_test @ Wt\n",
        "countst_test = logitst_test.exp()\n",
        "probst_test = countst_test / countst_test.sum(1, keepdim=True)\n",
        "losst_test = -probst_test[torch.arange(yt_test.nelement()), yt_test].log().mean().item()\n",
        "print(f\"Dev Loss: {losst_test:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LzoGDU_OXvu",
        "outputId": "81d6e877-6ecc-4a5f-ceaa-9b88109e660b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.4721\n",
            "Dev Loss: 2.4700\n",
            "Dev Loss: 2.4694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using F.cross_entropy for loss"
      ],
      "metadata": {
        "id": "4egr5neJP7yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model with best lambda and evaluate on test data\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "Wt = torch.randn((54, 27), generator=g, requires_grad=True)\n",
        "\n",
        "# Train the model\n",
        "for k in range(500):\n",
        "    losst = F.cross_entropy(xt_train @ Wt, yt_train)\n",
        "    losst += best_lambda * Wt.pow(2).mean()\n",
        "\n",
        "    Wt.grad = None\n",
        "    losst.backward()\n",
        "    Wt.data += -1 * Wt.grad\n",
        "\n",
        "# Evaluate on train set\n",
        "losst = F.cross_entropy(xt_train @ Wt, yt_train).item()\n",
        "print(f'Train Loss: {losst:.4f}')\n",
        "\n",
        "# Evaluate on dev set\n",
        "losst_dev = F.cross_entropy(xt_dev @ Wt, yt_dev).item()\n",
        "print(f\"Dev Loss: {losst_dev:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "losst_test = F.cross_entropy(xt_test @ Wt, yt_test).item()\n",
        "print(f\"Test Loss: {losst_test:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MikQmfInPeqN",
        "outputId": "aa5da438-bbe9-4437-9889-c34d371f915c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.4721\n",
            "Dev Loss: 2.4700\n",
            "Test Loss: 2.4694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using F.cross_entropy is preferred as it is more efficient, faster, and less prone to errors.\n",
        "# Also takes care of any floating point overflow or underflow\n",
        "\n",
        "# F.cross_entropy takes care of:\n",
        "    # Softmax of logits\n",
        "    # Log\n",
        "    # NLL\n",
        "    # Mean"
      ],
      "metadata": {
        "id": "JtLz3ku1RK-7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SUMMARY\n",
        "\n",
        "# 1. Generate datasets using words\n",
        "# 2. Encode input dataset (and concat incase of trigram or more)\n",
        "# 3. Generate random weights for 27 Neurons\n",
        "# 4. Train the Model using loss-back propogation\n",
        "    # Use cross_entropy(logits) to calculate loss\n",
        "    # Add Regularization to limit Weight growth\n",
        "# 5. Evaluate on dev, test datasets\n",
        "# 6. Generate more samples using multinomial"
      ],
      "metadata": {
        "id": "46BQX4guRk4o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphic of Matrix Multiplication in Bigram and Trigram"
      ],
      "metadata": {
        "id": "6fUc_wUhZThl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram"
      ],
      "metadata": {
        "id": "0HN2cwHaZex7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# When we are doing the matrix maultiplication\n",
        "    # only 1 value of the one-hot encoded vector is non-zero\n",
        "    # So, although the input vector gets multiplied with all the weights of all Neurons\n",
        "    # Only 1 weight from each Neuron is selected as all other weights from the Neurons become 0 after the multiplication\n",
        "# So X @ W in a Bigram model simply indexes into a row of the Network\n",
        "    # (ith index weight of each Neuron, where i is the index of the non-zero element in input vector)"
      ],
      "metadata": {
        "id": "xIQn3pp_ZXjy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarly in trigram\n",
        "    # only 2 indexes are non-zero out of 54\n",
        "    # So the output is basically the sum of the weights of each neuron in the 2 non-zero index rows."
      ],
      "metadata": {
        "id": "EO1wZI4zaFA-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity let's consider our alphabet only has 3 characters, so including special sequence. 4 characters\n",
        "\n",
        "Matrix Multiplication:\n",
        "X @ W\n",
        "\n",
        "|         @    | Neuron 0 | Neuron 1 | Neuron 2 | Neuron 3 |\n",
        "| ----------- | -------- | -------- | -------- | -------- |\n",
        "| **Input 0** | `W₀₀`    | `W₀₁`    | `W₀₂`    | `W₀₃`    |\n",
        "| **Input 1** | `W₁₀`    | `W₁₁`    | `W₁₂`    | `W₁₃`    |\n",
        "| **Input 2** | `W₂₀`    | `W₂₁`    | `W₂₂`    | `W₂₃`    |\n",
        "| **Input 3** | `W₃₀`    | `W₃₁`    | `W₃₂`    | `W₃₃`    |\n",
        "\n",
        "Y \\= y0 + y1 + y2 + y3\n",
        "<br> = (x0\\*w00 , x0\\*w01 , x0\\*w02 , x0\\*w03)\n",
        "<br> \\+ (x1\\*w10 , x1\\*w11 , x1\\*w12 , x1\\*w13)\n",
        "<br> \\+ (x2\\*w20 , x2\\*w21 , x2\\*w22 , x2\\*w23)\n",
        "<br> \\+ (x3\\*w30 , x3\\*w31 , x3\\*w32 , x3\\*w33)\n",
        "\n",
        "For x0, x1, x2 = 0 & x3=1\n",
        "\n",
        "Y = (x3\\*w30 , x3\\*w31 , x3\\*w32 , x3\\*w33)\n",
        "<br> = [w30, w31, w32, w33]\n",
        "<br> = Row i of W (where i is the index of non-zero element in Input Vector\n",
        "\n",
        "Y = W[i]"
      ],
      "metadata": {
        "id": "HzFkoEEek5dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trigram"
      ],
      "metadata": {
        "id": "KAGaMCfs6r1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarly, 2 inputs are non zero. So the output will be the sum of individuals weights of the non-zero index's rows."
      ],
      "metadata": {
        "id": "Y9SGVkd0aXhm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_Q7wScm63pM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}