{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "HtRkX3czeig7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xxZCu7WwcQ5N"
      },
      "outputs": [],
      "source": [
        "# Collecting Words\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/AndrejKarpathy_NN_Hero/names.txt'\n",
        "words = open(path, 'r').read().splitlines()\n",
        "\n",
        "# Mapping\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3 # number of characters as input\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w+'.':\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "\n",
        "# Split the dataset (train: 80%, dev: 10%, test:10%)\n",
        "rs = 2147483647\n",
        "torch.manual_seed(42); # for reproduceability\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, train_size=0.8, random_state=rs, shuffle=True)\n",
        "X_dev, X_test, Y_dev, Y_test = train_test_split(X_temp, Y_temp, train_size=0.5, random_state=rs, shuffle=True)"
      ],
      "metadata": {
        "id": "tOUQONHSegku"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorchify Code: Add more classes and club layers into Sequential"
      ],
      "metadata": {
        "id": "Skda5gcGPYIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
        "        self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            self.out += self.bias\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "        # buffers (trained with a running 'momentum update')\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # calculate the forward pass\n",
        "        if self.training:\n",
        "            xmean = x.mean(0, keepdim=True) # batch mean\n",
        "            xvar = x.var(0, keepdim=True) # batch variance\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "        # update the buffers\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "class Tanh:\n",
        "    def __call__(self, x):\n",
        "        self.out = torch.tanh(x)\n",
        "        return self.out\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "class Embedding:\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "    def __call__(self, IX):\n",
        "        self.out = self.weight[IX]\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight]\n",
        "\n",
        "class Flatten:\n",
        "    def __call__(self, x):\n",
        "        self.out = x.view(x.shape[0], -1)\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "# Clubbing Multiple Layers into a Container\n",
        "\n",
        "class Sequential:\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [p for layer in self.layers for p in layer.parameters()]"
      ],
      "metadata": {
        "id": "lNXHJEIxu98w"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # dimensionality of the embedding vectors\n",
        "n_hidden = 200 # neurons in the hidden layer\n",
        "vocab_size = 27\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].weight *= 0.1 # make last layer less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRU1qK02vqrC",
        "outputId": "e02e3453-d3f2-4e0d-a3b8-f680aea0301d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "itrns = 200000\n",
        "lossi = []\n",
        "\n",
        "for i in range(itrns):\n",
        "    # minibatch\n",
        "    ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size, ))\n",
        "    Xb, Yb = X_train[ix], Y_train[ix]\n",
        "\n",
        "    # forward pass\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # nudge\n",
        "    lr = 0.1 if i < 150000 else 0.01\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    if i % 10000 == 0:\n",
        "        print(f'Loss on iteration {i}: {loss.item()} | Learning Rate: {lr}')\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "print(\"Final Loss: \", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDX__JD1xk_Q",
        "outputId": "885ba763-1e25-45c5-c1a6-5bee5c06b1bc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on iteration 0: 3.2935924530029297 | Learning Rate: 0.1\n",
            "Loss on iteration 10000: 2.29407000541687 | Learning Rate: 0.1\n",
            "Loss on iteration 20000: 1.7902637720108032 | Learning Rate: 0.1\n",
            "Loss on iteration 30000: 2.1642794609069824 | Learning Rate: 0.1\n",
            "Loss on iteration 40000: 2.1873393058776855 | Learning Rate: 0.1\n",
            "Loss on iteration 50000: 2.114886999130249 | Learning Rate: 0.1\n",
            "Loss on iteration 60000: 2.0209755897521973 | Learning Rate: 0.1\n",
            "Loss on iteration 70000: 2.0486178398132324 | Learning Rate: 0.1\n",
            "Loss on iteration 80000: 2.5024943351745605 | Learning Rate: 0.1\n",
            "Loss on iteration 90000: 2.294386386871338 | Learning Rate: 0.1\n",
            "Loss on iteration 100000: 1.882494330406189 | Learning Rate: 0.1\n",
            "Loss on iteration 110000: 2.1629228591918945 | Learning Rate: 0.1\n",
            "Loss on iteration 120000: 2.0981831550598145 | Learning Rate: 0.1\n",
            "Loss on iteration 130000: 1.984136700630188 | Learning Rate: 0.1\n",
            "Loss on iteration 140000: 2.0123836994171143 | Learning Rate: 0.1\n",
            "Loss on iteration 150000: 2.3687987327575684 | Learning Rate: 0.01\n",
            "Loss on iteration 160000: 1.7723197937011719 | Learning Rate: 0.01\n",
            "Loss on iteration 170000: 2.4408366680145264 | Learning Rate: 0.01\n",
            "Loss on iteration 180000: 2.7072103023529053 | Learning Rate: 0.01\n",
            "Loss on iteration 190000: 2.090836763381958 | Learning Rate: 0.01\n",
            "Final Loss:  2.1815147399902344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put layers into eval mode\n",
        "for layer in model.layers:\n",
        "    layer.training = False\n",
        "\n",
        "# DEV & TEST LOSS\n",
        "@torch.no_grad() # decorator to disable grad tracking for any vars inside the function\n",
        "def split_loss(split):\n",
        "    x, y = {\n",
        "        'train': (X_train, Y_train),\n",
        "        'val': (X_dev, Y_dev),\n",
        "        'test': (X_test, Y_test)\n",
        "    }[split]\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    print(split, loss.item())\n",
        "\n",
        "split_loss('val')\n",
        "split_loss('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j8_TPBqzESR",
        "outputId": "a0250113-dabb-4aee-e5f7-4b6a401ce244"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val 2.114558219909668\n",
            "test 2.1130573749542236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "        logits = model(torch.tensor([context]))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "        context = context[1:] + [ix]\n",
        "        out.append(ix)\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlcsnXvnzaw1",
        "outputId": "8c47346c-ff77-41cc-ef4e-e944d33aae5f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mona.\n",
            "kayah.\n",
            "seel.\n",
            "ndhonalee.\n",
            "thruthadrieg.\n",
            "azeled.\n",
            "elin.\n",
            "shi.\n",
            "jen.\n",
            "eden.\n",
            "estanaraelyzion.\n",
            "kamin.\n",
            "shub.\n",
            "rishiriel.\n",
            "kin.\n",
            "renlynn.\n",
            "novana.\n",
            "ubakynder.\n",
            "yarue.\n",
            "eli.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "4B5gfhku0ZwH",
        "outputId": "c7d38248-bbc0-4636-d958-481c01537bb8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e159da05c50>]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the loss looks too oscillating, no clear pattern\n",
        "# let's take the mean of each 1000 iterations's loss logs\n",
        "\n",
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "F3blqYjxF4Eh",
        "outputId": "e0784251-2f3f-482a-e730-afaa95adeec9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dilated Causal Convolutional layers\n",
        "\n",
        "Let's use 8 characters as input, and instead of squashing them into an equation in a single layer, let's do it progressively, 2 characters at a time\n",
        "\n",
        "![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%2Fid%2FOIP.SwYimoeSeEA2vxum9bP_jgHaDl%3Fr%3D0%26pid%3DApi&f=1&ipt=0cd9b51e641c98dbd5df9a0a242822b0bb0aad3b3ebd11ea6112b4b04c3102ae&ipo=images)"
      ],
      "metadata": {
        "id": "FbhZXbQuOSK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8 # number of characters as input\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w+'.':\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "\n",
        "# Split the dataset (train: 80%, dev: 10%, test:10%)\n",
        "rs = 2147483647\n",
        "torch.manual_seed(42); # for reproduceability\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, train_size=0.8, random_state=rs, shuffle=True)\n",
        "X_dev, X_test, Y_dev, Y_test = train_test_split(X_temp, Y_temp, train_size=0.5, random_state=rs, shuffle=True)"
      ],
      "metadata": {
        "id": "9wNEqTG5GHSz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # dimensionality of the embedding vectors\n",
        "n_hidden = 200 # neurons in the hidden layer\n",
        "vocab_size = 27\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].weight *= 0.1 # make last layer less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56b861c-4b8c-443e-f913-c1f10a6c8407",
        "id": "WhvfGYkHPCd0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "itrns = 200000\n",
        "lossi = []\n",
        "\n",
        "for i in range(itrns):\n",
        "    # minibatch\n",
        "    ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size, ))\n",
        "    Xb, Yb = X_train[ix], Y_train[ix]\n",
        "\n",
        "    # forward pass\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # nudge\n",
        "    lr = 0.1 if i < 150000 else 0.01\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    if i % 10000 == 0:\n",
        "        print(f'Loss on iteration {i}: {loss.item()} | Learning Rate: {lr}')\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "print(\"Final Loss: \", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48381f2-e323-4b84-b80a-aa602639b394",
        "id": "hNvwn8OBPCd1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on iteration 0: 3.3169336318969727 | Learning Rate: 0.1\n",
            "Loss on iteration 10000: 2.5022454261779785 | Learning Rate: 0.1\n",
            "Loss on iteration 20000: 2.447808027267456 | Learning Rate: 0.1\n",
            "Loss on iteration 30000: 2.334378480911255 | Learning Rate: 0.1\n",
            "Loss on iteration 40000: 2.164828062057495 | Learning Rate: 0.1\n",
            "Loss on iteration 50000: 2.0723536014556885 | Learning Rate: 0.1\n",
            "Loss on iteration 60000: 2.169372797012329 | Learning Rate: 0.1\n",
            "Loss on iteration 70000: 1.9889376163482666 | Learning Rate: 0.1\n",
            "Loss on iteration 80000: 1.8500629663467407 | Learning Rate: 0.1\n",
            "Loss on iteration 90000: 1.6178162097930908 | Learning Rate: 0.1\n",
            "Loss on iteration 100000: 1.8165514469146729 | Learning Rate: 0.1\n",
            "Loss on iteration 110000: 2.108165740966797 | Learning Rate: 0.1\n",
            "Loss on iteration 120000: 2.414097547531128 | Learning Rate: 0.1\n",
            "Loss on iteration 130000: 2.149364709854126 | Learning Rate: 0.1\n",
            "Loss on iteration 140000: 2.1517157554626465 | Learning Rate: 0.1\n",
            "Loss on iteration 150000: 2.1227049827575684 | Learning Rate: 0.01\n",
            "Loss on iteration 160000: 2.020482063293457 | Learning Rate: 0.01\n",
            "Loss on iteration 170000: 1.8329007625579834 | Learning Rate: 0.01\n",
            "Loss on iteration 180000: 2.3748974800109863 | Learning Rate: 0.01\n",
            "Loss on iteration 190000: 2.1712260246276855 | Learning Rate: 0.01\n",
            "Final Loss:  2.288226842880249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put layers into eval mode\n",
        "for layer in model.layers:\n",
        "    layer.training = False\n",
        "\n",
        "# DEV & TEST LOSS\n",
        "@torch.no_grad() # decorator to disable grad tracking for any vars inside the function\n",
        "def split_loss(split):\n",
        "    x, y = {\n",
        "        'train': (X_train, Y_train),\n",
        "        'val': (X_dev, Y_dev),\n",
        "        'test': (X_test, Y_test)\n",
        "    }[split]\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    print(split, loss.item())\n",
        "\n",
        "split_loss('val')\n",
        "split_loss('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b694b251-9a97-4bf4-f936-1ed0707ba57a",
        "id": "YenY7g9QPCd1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val 2.0325732231140137\n",
            "test 2.032092809677124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "        logits = model(torch.tensor([context]))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "        context = context[1:] + [ix]\n",
        "        out.append(ix)\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046e1c17-ea74-4de4-9838-570baa64ade5",
        "id": "kWj6S1AMPCd2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mohani.\n",
            "yazziel.\n",
            "madyn.\n",
            "alareth.\n",
            "stendra.\n",
            "grazeem.\n",
            "melin.\n",
            "shyloe.\n",
            "leighsen.\n",
            "anarielle.\n",
            "malaia.\n",
            "noshaber.\n",
            "shiriel.\n",
            "kindreel.\n",
            "konnie.\n",
            "casuma.\n",
            "geda.\n",
            "jamell.\n",
            "elsyla.\n",
            "jayson.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Log\n",
        "- Original (context: 3 chars + 200 hidden neurons, 12K params): train- 2.18, val-2.114, test-2.113\n",
        "- context: 3->8 (22k params): train-2.28, val-2.03, test-2.03"
      ],
      "metadata": {
        "id": "dJ9_wxDmRGIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to club together 2 characters in each level\n",
        "# let's take an example of what we are currently doing in our Linear layer\n",
        "# eg: take 4 inputs, 8 characters * 10 dimensional vectors = 80 dimensions, 200 hidden neurons in first layer\n",
        "emb = torch.randn(4, 80)\n",
        "wet = torch.randn(80, 200)\n",
        "bis = torch.randn(200)\n",
        "(emb @ wet + bis).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ1SDy_GRn2a",
        "outputId": "728735d4-ab7d-4db7-9b97-c9066f058acc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instead of squashing like that, now we will take only a combination of 2 characters, 20 dimensional vectors in each layer\n",
        "emb = torch.randn(4, 8, 10)\n",
        "\n",
        "l1 = (emb.view(4, -1, 20) @ torch.randn(20, 200) + torch.randn(200))\n",
        "print('l1: ', l1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXy53ySNVcf4",
        "outputId": "38c551cd-36c6-4289-d9b7-40d9a0b55d91"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l1:  torch.Size([4, 4, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
        "        self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            self.out += self.bias\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "        # buffers (trained with a running 'momentum update')\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # calculate the forward pass\n",
        "        if self.training:\n",
        "            xmean = x.mean(0, keepdim=True) # batch mean\n",
        "            xvar = x.var(0, keepdim=True) # batch variance\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "        # update the buffers\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "class Tanh:\n",
        "    def __call__(self, x):\n",
        "        self.out = torch.tanh(x)\n",
        "        return self.out\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "class Embedding:\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "    def __call__(self, IX):\n",
        "        self.out = self.weight[IX]\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight]\n",
        "\n",
        "class FlattenConsecutiveN:\n",
        "\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, T, C = x.shape\n",
        "        x = x.view(B, T//self.n, C * self.n)\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.squeeze(1)\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "# Clubbing Multiple Layers into a Container\n",
        "\n",
        "class Sequential:\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [p for layer in self.layers for p in layer.parameters()]"
      ],
      "metadata": {
        "id": "4jZAtJhtWO6S"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # dimensionality of the embedding vectors\n",
        "n_hidden = 200 # neurons in the hidden layer\n",
        "vocab_size = 27\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd), # 4, 8, 10\n",
        "    FlattenConsecutiveN(block_size), # 4, 80\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].weight *= 0.1 # make last layer less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9bf2e4-a72e-45aa-e6a5-84afa371eaaa",
        "id": "t1982FMUZP19"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(low=0, high=X_train.shape[0], size=(4, ))\n",
        "Xb, Yb = X_train[ix], Y_train[ix]\n",
        "logits = model(Xb)\n",
        "\n",
        "print(Xb.shape)\n",
        "Xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyrGBDP-aNTE",
        "outputId": "7d1de2f1-7549-4391-820d-762dc32ba7c5"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0, 18,  8,  5, 20, 20],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0, 20],\n",
              "        [ 0,  0,  0,  0,  0,  0,  1, 14],\n",
              "        [ 0,  0,  0, 19, 15, 14,  1, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7HXGvs-Z2-6",
        "outputId": "40153fff-408d-41cc-8dd4-4c92495aa6bd"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding : (4, 8, 10)\n",
            "FlattenConsecutiveN : (4, 80)\n",
            "Linear : (4, 200)\n",
            "BatchNorm1d : (4, 200)\n",
            "Tanh : (4, 200)\n",
            "Linear : (4, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Update the consecutive N size"
      ],
      "metadata": {
        "id": "4bz3XlRAaj14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # dimensionality of the embedding vectors\n",
        "n_hidden = 68 # neurons in the hidden layer\n",
        "vocab_size = 27\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd), # 4, 8, 10\n",
        "    FlattenConsecutiveN(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutiveN(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutiveN(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].weight *= 0.1 # make last layer less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUGIwXZfaiuw",
        "outputId": "ab48548a-6304-4ea7-869f-41f9b79db5db"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(low=0, high=X_train.shape[0], size=(4, ))\n",
        "Xb, Yb = X_train[ix], Y_train[ix]\n",
        "logits = model(Xb)\n",
        "\n",
        "print(Xb.shape)\n",
        "Xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlHSibGRaw8K",
        "outputId": "795444a4-4ef9-4fd1-a5cf-f6277d063fee"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0, 10,  1, 13,  9, 12],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  9, 25,  1, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZvJRXXba0np",
        "outputId": "30cd73c7-2b17-437a-b0b8-3d55297c0288"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding : (4, 8, 10)\n",
            "FlattenConsecutiveN : (4, 4, 20)\n",
            "Linear : (4, 4, 68)\n",
            "BatchNorm1d : (4, 4, 68)\n",
            "Tanh : (4, 4, 68)\n",
            "FlattenConsecutiveN : (4, 2, 136)\n",
            "Linear : (4, 2, 68)\n",
            "BatchNorm1d : (4, 2, 68)\n",
            "Tanh : (4, 2, 68)\n",
            "FlattenConsecutiveN : (4, 136)\n",
            "Linear : (4, 68)\n",
            "BatchNorm1d : (4, 68)\n",
            "Tanh : (4, 68)\n",
            "Linear : (4, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "itrns = 200000\n",
        "lossi = []\n",
        "\n",
        "for i in range(itrns):\n",
        "    # minibatch\n",
        "    ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size, ))\n",
        "    Xb, Yb = X_train[ix], Y_train[ix]\n",
        "\n",
        "    # forward pass\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # nudge\n",
        "    lr = 0.1 if i < 150000 else 0.01\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    if i % 10000 == 0:\n",
        "        print(f'Loss on iteration {i}: {loss.item()} | Learning Rate: {lr}')\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "print(\"Final Loss: \", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0209c56-3298-4c6f-d5bd-062f7727d8a6",
        "id": "L9ghR9D6ZP19"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on iteration 0: 3.2879951000213623 | Learning Rate: 0.1\n",
            "Loss on iteration 10000: 1.9877878427505493 | Learning Rate: 0.1\n",
            "Loss on iteration 20000: 1.6482698917388916 | Learning Rate: 0.1\n",
            "Loss on iteration 30000: 2.16200852394104 | Learning Rate: 0.1\n",
            "Loss on iteration 40000: 1.9285345077514648 | Learning Rate: 0.1\n",
            "Loss on iteration 50000: 2.2006118297576904 | Learning Rate: 0.1\n",
            "Loss on iteration 60000: 1.6384074687957764 | Learning Rate: 0.1\n",
            "Loss on iteration 70000: 2.066401481628418 | Learning Rate: 0.1\n",
            "Loss on iteration 80000: 1.9437100887298584 | Learning Rate: 0.1\n",
            "Loss on iteration 90000: 2.096543788909912 | Learning Rate: 0.1\n",
            "Loss on iteration 100000: 1.828500509262085 | Learning Rate: 0.1\n",
            "Loss on iteration 110000: 1.9100549221038818 | Learning Rate: 0.1\n",
            "Loss on iteration 120000: 2.579824447631836 | Learning Rate: 0.1\n",
            "Loss on iteration 130000: 2.1416876316070557 | Learning Rate: 0.1\n",
            "Loss on iteration 140000: 2.4631359577178955 | Learning Rate: 0.1\n",
            "Loss on iteration 150000: 2.6366991996765137 | Learning Rate: 0.01\n",
            "Loss on iteration 160000: 1.9873230457305908 | Learning Rate: 0.01\n",
            "Loss on iteration 170000: 2.070669651031494 | Learning Rate: 0.01\n",
            "Loss on iteration 180000: 1.4551469087600708 | Learning Rate: 0.01\n",
            "Loss on iteration 190000: 1.6939332485198975 | Learning Rate: 0.01\n",
            "Final Loss:  2.167942762374878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put layers into eval mode\n",
        "for layer in model.layers:\n",
        "    layer.training = False\n",
        "\n",
        "# DEV & TEST LOSS\n",
        "@torch.no_grad() # decorator to disable grad tracking for any vars inside the function\n",
        "def split_loss(split):\n",
        "    x, y = {\n",
        "        'train': (X_train, Y_train),\n",
        "        'val': (X_dev, Y_dev),\n",
        "        'test': (X_test, Y_test)\n",
        "    }[split]\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    print(split, loss.item())\n",
        "\n",
        "split_loss('val')\n",
        "split_loss('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d80b15-6666-465f-bfe4-30f4b1d507b5",
        "id": "0tcMhSh3ZP1-"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val 2.038123846054077\n",
            "test 2.0357651710510254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "        logits = model(torch.tensor([context]))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "        context = context[1:] + [ix]\n",
        "        out.append(ix)\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03372cbe-7c9a-49c4-a2e9-f7d7cc47a322",
        "id": "EhYIzvL7ZP1-"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "montaymyah.\n",
            "seelen.\n",
            "hayla.\n",
            "rensrette.\n",
            "raege.\n",
            "zehed.\n",
            "eliah.\n",
            "miloe.\n",
            "leighnes.\n",
            "anarielle.\n",
            "malaia.\n",
            "noshub.\n",
            "rilai.\n",
            "jestin.\n",
            "joselynn.\n",
            "novalfou.\n",
            "zenne.\n",
            "ruyah.\n",
            "faeli.\n",
            "kayshis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnDNF3Qle55c",
        "outputId": "bbf37b70-f9bb-46c9-aad9-0e2352ce3db7"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding : (1, 8, 10)\n",
            "FlattenConsecutiveN : (1, 4, 20)\n",
            "Linear : (1, 4, 68)\n",
            "BatchNorm1d : (1, 4, 68)\n",
            "Tanh : (1, 4, 68)\n",
            "FlattenConsecutiveN : (1, 2, 136)\n",
            "Linear : (1, 2, 68)\n",
            "BatchNorm1d : (1, 2, 68)\n",
            "Tanh : (1, 2, 68)\n",
            "FlattenConsecutiveN : (1, 136)\n",
            "Linear : (1, 68)\n",
            "BatchNorm1d : (1, 68)\n",
            "Tanh : (1, 68)\n",
            "Linear : (1, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Log\n",
        "\n",
        "- Original (context: 3 chars + 200 hidden neurons, 12K params): train- 2.18, val-2.114, test-2.113\n",
        "- context: 3->8 (22k params): train-2.28, val-2.03, test-2.03\n",
        "- hierarchical-dilated: 2 consecutive numbers(22k params): train-2.16 , val-2.03 , test- 2.03"
      ],
      "metadata": {
        "id": "lAWP1zSQcWpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Debugging BatchNorm to take 3d tensors as input"
      ],
      "metadata": {
        "id": "IOwTH-J1f9iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
        "        self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            self.out += self.bias\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "        # parameters (trained with backprop)\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "        # buffers (trained with a running 'momentum update')\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # calculate the forward pass\n",
        "        if self.training:\n",
        "            if x.ndim ==2:\n",
        "                dims_reduce = 0\n",
        "            elif x.ndim ==3:\n",
        "                dims_reduce = (0, 1)\n",
        "            xmean = x.mean(dims_reduce, keepdim=True) # batch mean\n",
        "            xvar = x.var(dims_reduce, keepdim=True) # batch variance\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "        self.out = self.gamma * xhat + self.beta\n",
        "        # update the buffers\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "class Tanh:\n",
        "    def __call__(self, x):\n",
        "        self.out = torch.tanh(x)\n",
        "        return self.out\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "class Embedding:\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "    def __call__(self, IX):\n",
        "        self.out = self.weight[IX]\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight]\n",
        "\n",
        "class FlattenConsecutiveN:\n",
        "\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, T, C = x.shape\n",
        "        x = x.view(B, T//self.n, C * self.n)\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.squeeze(1)\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "# Clubbing Multiple Layers into a Container\n",
        "\n",
        "class Sequential:\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [p for layer in self.layers for p in layer.parameters()]"
      ],
      "metadata": {
        "id": "7yk5u0trcSdI"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # dimensionality of the embedding vectors\n",
        "n_hidden = 68 # neurons in the hidden layer\n",
        "vocab_size = 27\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd), # 4, 8, 10\n",
        "    FlattenConsecutiveN(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutiveN(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    FlattenConsecutiveN(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].weight *= 0.1 # make last layer less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e6d306-b136-4d97-9730-d274e3a900eb",
        "id": "GgSku0W_h5OH"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "itrns = 200000\n",
        "lossi = []\n",
        "\n",
        "for i in range(itrns):\n",
        "    # minibatch\n",
        "    ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size, ))\n",
        "    Xb, Yb = X_train[ix], Y_train[ix]\n",
        "\n",
        "    # forward pass\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # nudge\n",
        "    lr = 0.1 if i < 150000 else 0.01\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    if i % 10000 == 0:\n",
        "        print(f'Loss on iteration {i}: {loss.item()} | Learning Rate: {lr}')\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "print(\"Final Loss: \", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3134e079-a054-4048-8d6b-84c6882b1721",
        "id": "7c5opYSVh5OK"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on iteration 0: 3.2976396083831787 | Learning Rate: 0.1\n",
            "Loss on iteration 10000: 2.2582876682281494 | Learning Rate: 0.1\n",
            "Loss on iteration 20000: 2.0415730476379395 | Learning Rate: 0.1\n",
            "Loss on iteration 30000: 1.936320424079895 | Learning Rate: 0.1\n",
            "Loss on iteration 40000: 1.800300121307373 | Learning Rate: 0.1\n",
            "Loss on iteration 50000: 1.9813306331634521 | Learning Rate: 0.1\n",
            "Loss on iteration 60000: 1.8723562955856323 | Learning Rate: 0.1\n",
            "Loss on iteration 70000: 2.033402442932129 | Learning Rate: 0.1\n",
            "Loss on iteration 80000: 1.9158909320831299 | Learning Rate: 0.1\n",
            "Loss on iteration 90000: 2.1224076747894287 | Learning Rate: 0.1\n",
            "Loss on iteration 100000: 1.6351393461227417 | Learning Rate: 0.1\n",
            "Loss on iteration 110000: 2.3161938190460205 | Learning Rate: 0.1\n",
            "Loss on iteration 120000: 1.7075954675674438 | Learning Rate: 0.1\n",
            "Loss on iteration 130000: 1.497706651687622 | Learning Rate: 0.1\n",
            "Loss on iteration 140000: 1.9173574447631836 | Learning Rate: 0.1\n",
            "Loss on iteration 150000: 2.2600090503692627 | Learning Rate: 0.01\n",
            "Loss on iteration 160000: 1.6468818187713623 | Learning Rate: 0.01\n",
            "Loss on iteration 170000: 1.7984143495559692 | Learning Rate: 0.01\n",
            "Loss on iteration 180000: 2.018073558807373 | Learning Rate: 0.01\n",
            "Loss on iteration 190000: 1.53773832321167 | Learning Rate: 0.01\n",
            "Final Loss:  1.8498761653900146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put layers into eval mode\n",
        "for layer in model.layers:\n",
        "    layer.training = False\n",
        "\n",
        "# DEV & TEST LOSS\n",
        "@torch.no_grad() # decorator to disable grad tracking for any vars inside the function\n",
        "def split_loss(split):\n",
        "    x, y = {\n",
        "        'train': (X_train, Y_train),\n",
        "        'val': (X_dev, Y_dev),\n",
        "        'test': (X_test, Y_test)\n",
        "    }[split]\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    print(split, loss.item())\n",
        "\n",
        "split_loss('val')\n",
        "split_loss('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7880e282-60dd-46ea-b97c-159b31342910",
        "id": "D1z5XIPhh5OL"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val 2.030392646789551\n",
            "test 2.022149085998535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "        logits = model(torch.tensor([context]))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "        context = context[1:] + [ix]\n",
        "        out.append(ix)\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d1429e-cd5c-4cb1-92b6-ca49064be870",
        "id": "qTejyh5yh5OL"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mordal.\n",
            "yazlee.\n",
            "lendyn.\n",
            "alareth.\n",
            "stejgra.\n",
            "graden.\n",
            "daelin.\n",
            "shivoph.\n",
            "edelieana.\n",
            "arleigh.\n",
            "malara.\n",
            "noshub.\n",
            "roshimae.\n",
            "trinio.\n",
            "jenil.\n",
            "novaleiu.\n",
            "zayven.\n",
            "jamell.\n",
            "eliyah.\n",
            "jayston.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7465054e-0a28-4dda-8661-19429208d70c",
        "id": "uU-9YYphh5OL"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding : (1, 8, 10)\n",
            "FlattenConsecutiveN : (1, 4, 20)\n",
            "Linear : (1, 4, 68)\n",
            "BatchNorm1d : (1, 4, 68)\n",
            "Tanh : (1, 4, 68)\n",
            "FlattenConsecutiveN : (1, 2, 136)\n",
            "Linear : (1, 2, 68)\n",
            "BatchNorm1d : (1, 2, 68)\n",
            "Tanh : (1, 2, 68)\n",
            "FlattenConsecutiveN : (1, 136)\n",
            "Linear : (1, 68)\n",
            "BatchNorm1d : (1, 68)\n",
            "Tanh : (1, 68)\n",
            "Linear : (1, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Log\n",
        "\n",
        "- Original (context: 3 chars + 200 hidden neurons, 12K params): train- 2.18, val-2.114, test-2.113\n",
        "- context: 3->8 (22k params): train-2.28, val-2.03, test-2.03\n",
        "- hierarchical-dilated: 2 consecutive numbers(22k params): train-2.16 , val-2.03 , test- 2.03\n",
        "- BatchNorm for 3D tensors (22k params): train- , val-, test-"
      ],
      "metadata": {
        "id": "MZ-Vqy30h5OL"
      }
    }
  ]
}